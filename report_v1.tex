
\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\begin{document}

{%%%
%\sffamily 　
\thispagestyle{empty}
\centering
\Large
%~\vspace{\fill}
{\Large Estimation of Conductivities in a 2D Non-Linear Heat Conduction Problem}


\vspace{0.5cm}



\begin{normalsize}
Aravind Sankaran (351286)\\
Krishnaswamy Veluswamy(11111)\\ 
Ting-Jui Hsu(351218)

\end{normalsize}


\vspace{0.5cm}


\begin{normalsize}
\textit{guided by}\\
Markus Towara

\end{normalsize}

\vspace{0.5cm}


\begin{normalsize}
Software and Tools for Computational Engineering\\ 
Department of Computer Science\\ 
RWTH Aachen University\\ 
D-52056 Aachen, Germany\\

\end{normalsize}

\vspace{0.5cm}


\begin{normalsize}
\textit{for}\\
fulfillment of the course “Simulation Science Laboratory”

\end{normalsize}

\vspace{0.5cm}

{\normalsize $28^{th}$ Febuary 2016}

\vspace{\fill}
\pagebreak 


%in the\\[1em]
%\vspace{3.5cm}
%\vspace{\fill}
}

{
\thispagestyle{empty}
%\sffamily
\normalsize
\begin{center}
{\large \textbf{Abstract}}
\end{center}
The unknown distribution of the heat conductivity along the surface of a material is often important for industrial application and scientific research. It’s difficult or even not possible to directly measure the heat conductivity, while measuring temperature is not so difficult. The purpose of this project is to develop a software tool, that calibrates a 2 dimensional surface with constant density and unknown heat conductivities using experimentally obtained real world measurements of temperature distribution. This tool has been developed using C++.\\
\\
Finite difference methods have been used for solving the non-linear heat conductivity equation with Dirichlet boundary conditions and a constant heat source inside the domain. The conductivity grid resolution has been separated from the resolution of temperature distribution. The solver has been parallelized with MPI by decomposing the domain. Explicit $4^{th}$ order Runge-kutta scheme is accurate up to $4^{th}$ order in time. But the stability of this scheme is limited by the CFL conditions. For larger grid sizes, the time step required to maintain stability becomes smaller. Thus, for longer simulation time and larger grid sizes, the time required to solve the heat equation by this method becomes higher. Fully implicit method is unconditionally stable, but requires solving a linear system for each time step. This method is less scalable than explicit schemes.\\
\\
The conductivity distribution is estimated by minimizing the least square estimate of the difference in calculated and observed temperature distribution using Gradient-descent method. Gradient computations with Finite difference and Adjoint mode of Algorithmic differentiation have been compared. Calculating the gradient by Finite difference becomes tedious if the number of parameters to be estimated becomes larger. However, for the given problem, the computation time of each gradient by Adjoint mode AD is independent of the parameter size, but it is bounded by the memory availability. We have used DCO library for computing the gradient by Algorithmic differentiation.\\
\\
For the purpose of testing, and gathering results, the observed temperature has been taken from the simulation and appended with some noise which is standard normally distributed with variance 0.001. The parameter estimation along the surface of a Steel plate has been tested. However, the Steepest descent method takes too many iterations to converge for the given problem as the parameter size increases. This is because the above mentioned cost function becomes less sensitive as the conductivity points to be estimated on a given surface increases.

}

\tableofcontents
\thispagestyle{empty}


\chapter{Introduction}
\setcounter{page}{1}
To estimate the variation in conductivity along the surface of a homogeneous material*, the heat conduction along the 2D surface have to be simulated. This chapter explains the details of the problem, the solution approaches and the bottlenecks.\\

\begin{small}
\begin{flushleft}
 *  We assume constant density along the surface of the material under consideration
 \end{flushleft} 
\end{small}

\section{Problem Definition}
Heat is an energy that flows from higher temperature to lower temperature. Conduction is a method of heat transfer that occurs by  the movement of electrons from atom to atom .Thus, densely packed materials have higher conduction. The heat conduction in 2D can be modeled using the following partial differential equation:
\begin{equation}
\frac{\partial u}{\partial t}=k \bigtriangledown^2(u)
\end{equation}
where,\\
$u$: Temperature\\
$t$: Time\\
$k$: Thermal diffusivity of the material\\
\\
Heat conduction depends on the property of the material, and the “Thermal diffusivity (k)” encodes this dependence in the above heat equation. Furthermore, thermal diffusivity holds the following equation: 

\begin{equation}
k=\frac{c}{\rho C_p}
\end{equation}
where,\\
$c$: Thermal conductivity\\
$\rho$: Density\\
$C_p$: Specific heat capacity\\
\\
Thermal conductivity is the measure of the quantity of thermal energy which flows through a conductor, in a given time, through a given volume and temperature difference. Hence it is a property of the material.

If we consider the heat source term, the equation becomes,
\begin{equation}
\frac{\partial u}{\partial t}=(\frac{c}{\rho C_p})\bigtriangledown^2(u)+\frac{Q_x}{\rho C_p}
\end{equation}
where,\\
$Q_x$: Temperature of heat source at point x

\subsection{Why should thermal conductivity of a homogeneous material vary?}
Consider a bar of homogeneous material (constant density) which is heated at one end (constant heat source) ,a sink at the other end and the other two sides being insulated. Physics of linear heat conduction tells us that the temperature at every point in the bar should become constant after reaching steady state. But this is under the assumption that the material under consideration has perfect molecular arrangement. But in reality, nothing in this universe is perfect. There are some minor variations in the temperature even after reaching steady state, because of irregularities in the surface of the material. To model this variation, the heat conductivity, c, is made to depend on the spatial dimension. Since the density and Specific heat capacity are still held constant in equation (1.3), we categorize the material to be homogeneous.  Hence, the given problem should not be confused with parameter estimation in a heterogeneous media, where different materials with varying densities are usually fused into a single bar. 

\subsection{The 2D Non linear Heat conduction equation for homogeneous materials:}

If c depends on the spatial dimensions, the 2D heat equation becomes
\begin{equation}
\frac{\partial u}{\partial t}=(\frac{1}{\rho C_p})\bigtriangledown^2(cu)+\frac{Q_x}{\rho C_p}
\end{equation}

But, 
\begin{equation}
\bigtriangledown^2(cu)=c_x \bigtriangledown^2(u)+\bigtriangledown(c) \bigtriangledown(u)+u_x \bigtriangledown^2(c)
\end{equation}

If $\Delta(c)$ is small, the variations, $\Delta(k)\approx 0$, since $\rho C_p \gg k$. Thus, $\Delta(c)$ has negligible effect on the heat equation.

Hence,
\begin{equation}
\bigtriangledown^2(cu) \approx c_x \bigtriangledown^2(u)
\end{equation}

Therefore, the 2D heat conduction equation for homogeneous materials is 

\begin{equation}
\frac{\partial u}{\partial t}=(\frac{c_x}{\rho C_p})\bigtriangledown^2(cu)+\frac{Q_x}{\rho C_p}
\end{equation}

\section{Solution approach}
The goal of our project is to determine the variations in conductivity along the surface of a homogeneous material.\\
\\
Solution steps:\\
\\
1)Numerically solve the heat equation using finite difference\\
The above heat equation is discretized in an equidistant 2D grid, and has been solved using explicit Runge-kutta scheme and fully implicit scheme. Each method has its own advantages and disadvantages, which have been discussed in detail. The grid is decomposed and the data is distributed among the processors. Each processor works on its local data and the boundary data in the ghost cells are communicated using MPI \\
\\
2) Estimating the Conductivities\\
To estimate the vector of conductivities, gradient descent approach has been used to minimize the following least square estimate.

\begin{equation}
\argmin_{\substack{U}} y= \sum_{\substack{i}}(U_i-O_i)^2
\end{equation}
Where,\\
$U_i$: Final temperature computed by the solver\\
$O_i$: Observed temperature\\
\\
The gradient computations using Finite difference and Adjoint mode algorithmic differentiation has been compared. We use dco for the computation of the gradient using algorithmic differentiation.

\section{Need for parallelization and Adjoint mode AD}
Parameter estimation requires the computation of gradient for every iteration of gradient descent.\\
For our least square estimate in equation (1.8),\\
\begin{center}
$f: R^N\mapsto R$\\
\end{center}
Where,\\
$N =n\ast n$\\
$n$= grid size in each dimension \\
\\
The gradient computation by finite difference requires solving the heat equation N times for every gradient. Hence for larger grid sizes, we have larger number of parameters to estimate, which means, the computation time for each gradient increases with increasing parameter size.

If we compute the gradient by adjoint method of Algorithmic differentiation, the heat equation have to be solved M times, where M is the size of the output vector. For our case, M = 1. Hence we get the gradient in a single run of the solver. However, this requires storing the entire graph of computations and reversing the computation flow. Hence this method is bounded by the amount of available memory. By parallelizing the heat equation and decomposing the domain in a distributed memory architecture, we acquire more memory for computing the adjoint, thereby pushing its upper bound. 

The gradient descent method requires solving the heat equation until convergence. For larger grid sizes, the time required for every solution increases. Hence parallelizing the heat equation is crucial for obtaining the parameters as quickly as possible.
%something need to add for the software part.
%The unknown properties and distribution of the heat conductivity is often a important for industrial application and scientific research. It's difficult or even not possible to directly measure the heat conductivity, while measuring temperature is not so difficult. With the measured temperature distribution and some parameter fitting techniques, we can determine the unknown distribution of heat conductivity.
%
%Our project can be divided into two parts, simulation part and estimation part. In simulation part, we use fully implicit method and explicit Runga Kutta method to solve a 2 dimension heat equation. In estimate part, we take the result from the simulation as input and use steepest descent method to fit back heat conductivity.
% 
%Each of these methods has its own limitation. Explicit method is easy to implement, but not stable. Implicit method is guarantee to be stable, but it is usually computational intensive. For estimation, steepest descent method does not always give the best parameter set. We would discuss more details of these limitations later in the report. 
% 
%We mainly use C++ for our report. For Library, we use Message Passing Interface (MPI) for paralleling  and using dco library for algorithmic differentiation.
%
%The purpose of this report is to study how precise and stable can steepest descent method fit back the parameter by showing some numerical experiments and also trying to accelerate iterations and increase the precision of the final result.  

\chapter{Problem Setting and Solution Methods}
\section{Problem Formulation}
%https://en.wikipedia.org/wiki/Heat_equation
%https://en.wikipedia.org/wiki/Thermal_diffusivity

The main model problem would be discussed in our report is a 2D heat equation. We would like to know the final temperature distribution of the plate, when boundary conditions are given temperature on borders and heat source inside the domain. We approximate the derivatives of this problem with finite difference and we define an equidistant $n \times  n$ spatial grid. 

The temperature evolution with the time would be governed by the heat equation in the form 
\begin{equation}
{\frac{\partial u}{\partial t}}=\alpha({\frac{\partial^2 u}{\partial x^2}}+{\frac{\partial^2 u}{\partial y^2}}),\forall{x,y,t}\in \Omega,
\end{equation}

with $\alpha = {\frac{k}{c_p \rho}}$. Here $k$ is thermal conductivity, $\rho$ is density and $c_p$ is specific heat capacity. 
We can specify heat conductivity c for each point, i.e. heat conductivity is non-uniform. The function u must satisfy the above heat equation and we expect that the temperature at $t=T_{end}$ is determined by the time evolution of the equation.

With finite difference approximation, we can approximate the partial differential equation on grids points. Using Taylor's series approximation first on x-direction spatial grid we can derive
\begin{equation}
u(x_i+h,t^n)=u(x_i,t^n)+hu_x(x_i,t^n)+{\frac{h^2}{2}}u_{xx}(x_i,t^n)+{\frac{h^3}{6}}u_{xxx}(x_i,t^n)+\mathcal{O}(h^4)
\end{equation}
%\[\]
\begin{equation}
u(x_i-h,t^n)=u(x_i,t^n)-hu_x(x_i,t^n)+{\frac{h^2}{2}}u_{xx}(x_i,t^n)-{\frac{h^3}{6}}u_{xxx}(x_i,t^n)+\mathcal{O}(h^4) .
\end{equation}
%\[\]
Adding up two equation and we get
\begin{equation}
u_{xx}(x_i,t^n)={\frac{u(x_i+h,t^n)-2u(x_i,t^n)+u(x_i,t^n)}{h^2}}+\mathcal{O}(h^2)
\end{equation}
%\[\]
and same for y-direction
\begin{equation}
u_{yy}(y_i,t^n)={\frac{u(y_i+h,t^n)-2u(y_i,t^n)+u(y_i,t^n)}{h^2}}+\mathcal{O}(h^2).
\end{equation}
%\[\]
For time difference, we can also write a Taylor's series approximation.
\begin{equation}
u(x_i,t^n+\tau)=u(x_i,t^n)+\tau u_t(x_i,t^n)+\mathcal{O}(\tau^2) 
\end{equation}
%\[\]
and we get\begin{equation}
{\frac{u(x_i,t^n+\tau)-u(xi,t^n)}{\tau}}=u_t(x_i,t^n)+\mathcal{O}(\tau).
\end{equation} %\[\] 

\section{Explicit Scheme}
%change u into vertor bold font?
%\mathbf{u}

In explicit finite difference scheme, the temperature evolutes explicitly on the temperature at previous time step. The explicit finite difference discretization is simply obtained by the above Tayler's series approximation: 
\begin{equation}
{\frac{u^{n+1}_{i,j}-u^n_{i,j}}{\tau}}=c_{i,j}({\frac{u^n_{i,j+1}-2u^n_{i,j}+u^n_{i,j-1}}{h^2}}+{\frac{u^n_{i+1,j}-2u^n_{i,j}+u^n_{i-1,j}}{h^2}}).
\end{equation}
\[\]
%Consider adding the grid explanation for i j n.
This can be rearranged as following:
\begin{equation}
u^{n+1}_{i,j}=u^{n}_{i,j}+c_{i,j}{\frac{\tau}{h^2}}(u^n_{i,j+1}+u^n_{i+1,j}-4u^n_{i,j}+u^n_{i,j-1}+u^n_{i-1,j}).
\end{equation}
\[\]

We now get a relation between space and time derivatives at each $(x,t)\in \Omega$ with a discrete approximation. As long as we know $u^n_{i\pm 1,j}$,$u^n_{i,j}$, and $u^n_{i,j\pm 1}$, we can compute $u^{n+1}_{i,j}$ for the following time step. The scheme is completely defined when we apply initial conditions and boundary conditions on it.

In order to get higher accuracy, we implement Runge-Kutta method instead of first-order explicit method in our problem. As first-order explicit method, Runge-Kutta method is still a single-step method, with multiple stages per step however. 

To derive Runge-Kutta, once again we start from Taylor series approximation, 
\begin{equation}
u(t+\tau)=u(t)+\tau u'(t)+{\frac{\tau^2}{2}}u''(t)+\mathcal{O}(\tau^3).
\end{equation}
\[\]
Then we set first derivative as $u'(t)=f(t,u(t))$. From this we can get our second derivative by differentiating it, which is
\begin{equation}
u''(t)=f_t(t,u)+f_u(t,u)u'(t)=f_t(t,u)+f_u(t,u)f(t,u).
\end{equation}
 \[\] We substitute these into our Taylor series approximation and rewrite as following,
\begin{align} %without star align will index equation.
u(t+\tau)
=u(t)+\tau f(t,u)+{\frac{\tau^2}{2}}[f_t(t,u)+f_u(t,u)f(t,u)]+\mathcal{O}(\tau^3)\\
=u(t)+{\frac{\tau}{2}} f(t,u)+{\frac{\tau}{2}}[f(t,u)+\tau f_t(t,u)+\tau f_u(t,u)f(t,u)]+\mathcal{O}(\tau^3).  
\end{align}
With multivariate Taylor series approximation, we know $f(t+\tau,u+\tau f(t,u))=f(t,u)+\tau f_t(t,y)+\tau f_u(t,u)f(t,u)+\mathcal{O}(h^2).$ As a result, we get
\begin{equation}
u(t+\tau)=u(t)+{\frac{\tau}{2}}f(t,u)+{\frac{\tau}{2}}f(t+\tau,u+\tau f(t,u))+\mathcal{O}(\tau^3)
\end{equation}
 \[\] and in simple numerical form
\begin{equation}
 u^n+1=u^n+\tau ({\frac{1}{2}}k_1+{\frac{1}{2}}k_2),
 \end{equation} 
\[\]with 
\begin{align}
k_1=f(t_n,u^n),\\
k_2 = f(t_n+\tau, u^n+\tau k_1).
\end{align}
This is so called second-order Runge-Kutta method. However, to gain higher accuracy we use fourthe-order Runge-Kutta method and the method is as follow,
\begin{equation}
u^{n+1}=u^n+h[{\frac{k_1}{6}}+{\frac{k_2}{3}}+{\frac{k_3}{3}}+{\frac{k_4}{6}}]
\end{equation}
\[\]
with

\begin{align}
k_1=f(t_n,u^n),\\
k_2=f(t_n+{\frac{\tau}{2}},u^n+{\frac{\tau}{2}}k_1),\\
k_2=f(t_n+{\frac{\tau}{2}},u^n+{\frac{\tau}{2}}k_2),\\
k_2=f(t_n+\tau,u^n+\tau k_3).
\end{align}
The accuracy for the fourth-order Runge-Kutta method is $\mathcal{O}(\tau^5)$. However, this method also requires to evaluate the function $f$ four times per time step. One can easily see that in order to get higher order precision, we need more evaluations per time step. Generally speaking, it's not efficient to apply Runge-Kutta methods higher than fourth order. 

The main benefit of explicit finite difference method is its easiness of implementation and short computing time for each iteration. However, explicit finite difference method is stable only under this condition,
\begin{equation}
{\frac{c_{i,j}\tau}{h^2}}\leq {\frac{1}{2}}.
\end{equation}
\[\] Otherwise, the solution would become unstable and meaningless.

\section{Implicit Scheme}

To avoid unstable solution, we can use implicit finite difference schemes. We replace forward difference in time with a backward difference and get the implicit discretization of our heat equation as
\begin{equation}
{\frac{u^{n+1}_{i,j}-u^n_{i,j}}{\tau}}=c_{i,j}({\frac{u^{n+1}_{i,j+1}-2u^{n+1}_{i,j}+u^{n+1}_{i,j-1}}{h^2}}+{\frac{u^{n+1}_{i+1,j}-2u^{n+1}_{i,j}+u^{n+1}_{i-1,j}}{h^2}}).
\end{equation}
 \[\]
Once again this can be rearranged into
\begin{equation}
u^{n+1}_{i,j}+c_{i,j}{\frac{\tau}{h^2}}(-u^n_{i,j+1}+-u^n_{i+1,j}+4u^n_{i,j}-u^n_{i,j-1}-u^n_{i-1,j})=u^{n}_{i,j}.
\end{equation}
\[\]
In this scheme, even all $u^n_{i,j}$ are known, we cannot directly compute $u^{n+1}_{i,j} $. We need to solve a linear system at each time step, since all unknown variable $u^{n+1}_{i,j}$ are coupled with each other. We can write our linear system as follow \[\] 
\begin{equation}
AU^{n+1}=U^{n}
\end{equation}

\begin{equation}
U^{n+1}=\begin{bmatrix}
u^{n+1}_{1,1}\\
\vdots\\
u^{n+1}_{1,j_{max}}\\
u^{n+1}_{2,1}\\
\vdots\\
u^{n+1}_{2,j_{max}}\\
\vdots\\
u^{n+1}_{i_{max},j_{max}}\\
\end{bmatrix}
\end{equation}
\[
\]

\begin{equation}
A=\begin{bmatrix}
D_{(i=1)} & E_{(i=1)} & 0  & \cdots  & 0  \\
E_{(i=2)} & D_{(i=2)} & E_{(i=2)} &   & \vdots  \\
  & \ddots & \ddots &\ddots & \\
 \vdots &   & E_{(i=i_{max}-1)} & D_{(i=i_{max}-1)} & E_{(i=i_{max}-1)} \\
 0 & \cdots  &   & E_{(i=i_{max})} & D_{(i=i_{max})}    
\end{bmatrix}
\end{equation}
\[
\]

\begin{equation}
E=\begin{bmatrix}
-{\frac{c_{i,j}\tau}{h^2}} & 0 & & \\
0 & \ddots & \ddots & \\
  & \ddots & \ddots & \\
  &        & 0 & -{\frac{c_{i,j_{max}}\tau}{h^2}}  
\end{bmatrix}
\end{equation}
\[
\]

\begin{equation}
D=\begin{bmatrix}
1+2({\frac{c_{i,j}\tau}{h^2}}+{\frac{c_{i,j}\tau}{h^2}}) & -{\frac{c_{i,j}\tau}{h^2}} & &  \\
-{\frac{c_{i,j+1}\tau}{h^2}} & \ddots & \ddots & \\
& \ddots & \ddots & -{\frac{c_{i,j_{max}-1}\tau}{h^2}}\\
 &  & -{\frac{c_{i,j_{max}}\tau}{h^2}} & 1+2({\frac{c_{i,j_{max}}\tau}{h^2}}+{\frac{c_{i,j_{max}}\tau}{h^2}})
\end{bmatrix}
\end{equation}
\[
\]

\begin{equation}
U^{n}=\begin{bmatrix}
u^{n}_{bottom}\\
\vdots\\
u^{n}_{1,j_{max}}\\
u^{n}_{2,1}\\
\vdots\\
u^{n}_{2,j_{max}}\\
\vdots\\
u^{n}_{bottom}\\
\end{bmatrix}
\end{equation}
\[
\]


As we state in the beginning, the major advantage of implicit finite difference methods is that there is no certain condition for stableness. Therefore, we don't have restriction on the time step size, even if we have high resolution on the spatial part. However, the implicit finite difference method is more computational intensive on each iteration.

\section{Internal Heat Source}
%http://people.math.gatech.edu/~xchen/teach/pde/heat/Heat-Duhamel.pdf
%https://en.wikipedia.org/wiki/Duhamel%27s_principle

In our problem, boundary conditions are not only the temperature at borders (i.e, the north, east, south and west borders) but also heat sources inside our domain. This basically means we are trying to solve a nonhomogeneous problem instead of homogeneous one only. Our heat equation becomes
\begin{equation}
\begin{cases}
 {\frac{\partial u}{\partial t}}=\alpha({\frac{\partial^2 u}{\partial x^2}}+{\frac{\partial^2 u}{\partial y^2}})+{\frac{1}{c_p \rho}}q(t) \quad t>0,\\
 u(t=0)=0
\end{cases}
\end{equation}
\[\]  
According to Duhamel's Principle, an auxiliary problem of this is   
\begin{equation}
\begin{cases}
 {\frac{\partial u(t;s)}{\partial t}}=\alpha({\frac{\partial^2 u(t;s)}{\partial x^2}}+{\frac{\partial^2 u(t;s)}{\partial y^2}}) \quad t>s,\\
 u(s;s)=q(s;s).\\
\end{cases}  
\end{equation}
\[\]
Duhamel's Principle implies that we can move the heat source term into initial conditions and it is possible to derive the solution of a nonhomogeneous heat equation from the solution of a homogeneous heat equation with initial values.

Furthermore, our heat source term is independent of time, so Duhamel's Principle guarantees that we are allowed to absorb the heat source term into initial condition, apply normal numerical method to the problem and will get the correct solution in the end.

\section{Steepest Descent}

In order to fit parameters back to a problem, we choose steepest descent method. Given a cost function $J(\theta_1,...,\theta_n)$ on a search space, we update our parameter set,$(\theta_1,...,\theta_n)$, until our cost function $J(\theta_1,...,\theta_n)$ converges into a minimal. However, it is not guaranteed that the steepest descent method will stop at the real minimal, usually it stops at local minimal then get stuck in there.

In our report, we use square error function as our cost function $J(\theta_1,...,\theta_n)$, this is to say, when our hypothesis is $h_\theta(x)=\mathbf{\theta}^T \mathbf{x}$, our cost function is
\begin{equation}
 J(\theta_1,...,\theta_n)= \sum\limits_{i=1}^M (h_\theta(x_i)-y_i)^2          .
\end{equation} \[\] 
, in which $M$ is the number of our data and $y$ is the real result. The goal would be
\begin{equation}
\argmin_{\theta_0,...,\theta_n}J(\theta_0,...,\theta_n).
\end{equation}
 \[\]  
First, we randomly pick $\theta_0,...,\theta_n$ as our start point, then we update each $\theta$ as following
\begin{equation}
\theta_j := \theta_j - \alpha{\frac{\partial J(\theta_1,...,\theta_n)}{\partial \theta_j}},
\end{equation}
 \[\] in which $\alpha$ is the learning rate. After updating all parameters, we replace our cost function $J(\theta_1,...,\theta_n)$ with the new set of $(\theta_1,...,\theta_n)$. The next iteration will start with this new cost function and we iterate it until the cost function converge to its minimum. 


\chapter{Approach and Implementation}
\section{difference diffusivity and thermal conductivity}
%https://en.wikipedia.org/wiki/Specific_properties
%https://www.nde-ed.org/EducationResources/CommunityCollege/Materials/Physical_Chemical/ThermalConductivity.htm
%In general, steady-state techniques are useful when the temperature of the material does not change with time. => It's depend on temperature, especially on high temperature
%Thermal conductivity, k, often depends on temperature. Therefore the definitions listed below make sense when the thermal conductivity is temperature independent. Otherwise an representative mean value has to be considered


Before we get start, we need to clarify the difference between thermal diffusivity and thermal conductivity. Thermal diffusivity is \[\alpha = {\frac{k}{\rho c_p}}.\] Here $k$ is thermal conductivity, $\rho$ is density and $c_p$ is specific heat capacity. It is also denoted $k$, which is usually misunderstood with thermal conductivity and is not the parameter we want to fit back to our problem. On the other hand, thermal conductivity is a intrinsic property and relate to its ability by conduct heat. Thermal conductivity is often denoted $k$,$\kappa$ and $c$.   

It worth recurring to this, since we mistook these two parameter at the beginning of the project and it lead to the wrong simulation result.

\section{Compute the Gradient}
For steepest descent, we need to compute the gradient. For this, we have three choice, finite difference, adjoint mode and tagent linear mode. 

Finite difference:
\begin{equation}
F(x,\dot{x}):=F'(x)\dot{x}\approx {\frac{F(x+h\dot{x})-F(x)}{h}}
\end{equation}
\[\]
$\text{The computational cost of }F'(x)\, \text{is at} \, O(input) \cdot cost(F)$.
It is easy and straightforward to use finite difference method. However, when the step size become smaller and smaller, the truncation error will come in, since finite difference is an approximation method. 

Tangent linear mode:
\begin{equation}
F(x,\dot{x}):=F'(x)\dot{x}=\dot{y}
\end{equation}
\[\]
$\text{The computational cost of }F'(x)\, \text{is at} \, O(input) \cdot cost(F)$. Although we still need to evaluate function $F$ as many times as finite difference, we can get a more accurate result by using tangent linear mode.

Adjoint mode:
\begin{equation}
F(x,\bar{y}):=\bar{y}F'(x)=\bar{x}
\end{equation}
\[\]
$\text{The computational cost of }F'(x)\, \text{is at} \, O(output) \cdot cost(F)$. Different from two methods above, computing gradient with adjoint mode, the computational cost is linear to the output. For our case, it means we can get full gradient in one run. Since accuracy is not the important issue for us, we will mainly use adjoint mode to compute gradient for steepest descent method. 
     



\section{Gridsize for conductivity}
%Graph.
Although we can specify certain thermal conductivity to each points when simulating, at the beginning we are not going to fit parameter on each point. Instead, we divide our domain in to several block and the block size can be specified. The first reason is that usually the original conductivity is not different at each point but block. Second, since in estimation step, we doesn't know the distribution of the initial conductivity, rashly set the resolution to the grid point may cause overfitting and need more computation time. It would be proper to start with big block, and depending on the accuracy requirement, we can reduce the size of the block until we get the expected result.   


\section{gradient computation with AD}
\section{Jacobi iteration and Domain Decomposition}
\section{Validation }




\chapter{The Results and Discussion}
\section{Speed up with MPI}
\section{Gradient Evaluation with Different Methods}
\section{Convergence of Steepest Descent}
%convergence reach a plator and wait long to decrease again.



% Procedure for estimation

%@I. the problem
%@II. the approach
%III. the realization 
%IV.the results including a discussion.





\end{document}
